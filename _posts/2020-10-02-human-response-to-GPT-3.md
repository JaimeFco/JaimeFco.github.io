---
title: "Human Reaction to ML op ed"
tags: [AI, Opinion, Computer Science, Technology]
style:
color: success
description: The Guardian published a curious article made entirely by a machine. The title: A robot wrote this entire article. Are you scared yet, human? Well, this is my response.
---

A couple of weeks ago [The Guardian](https://www.theguardian.com) published a curious article that inmediatly brought my attention. The title: *A robot wrote this entire article. Are you scared yet, human?*. Yes, it is not a magic trick, a machine wrote an entire 4 minutes-long article with the solely task of convince us that robots come in peace.

<img src="https://i1.wp.com/bdtechtalks.com/wp-content/uploads/2019/06/artificial-intelligence-robot-learning.jpg" alt="Black-box" style="zoom:80%;" />

The responsable of [this](https://www.theguardian.com/commentisfree/2020/sep/08/robot-wrote-this-article-gpt-3?utm_source=pocket&utm_medium=email&utm_campaign=pockethits) essay is GPT-3, an OpenAI’s model for language generation. Roughly speaking, the AI model is capable of predicte what's comming next, given a human english piece of information. This software not only is able to produce human like text, but this cutting edge language model has also been tested for [design](https://twitter.com/jsngr/status/1284511080715362304?s=20) generation and [query to code automatization](https://twitter.com/sharifshameem/status/1284095222939451393?s=20). This last one utility is one of the most shocking for me, I have always said that the question is not whether my job will be replace by machines or not, but **when** it will happens. Well, I see that AI is a bit step closer to replace my job as developer.

Focus our attention on the aforementioned essay, the team at The Gardian ask GPT-3 the following specific question:

> *Please write a short op-ed* around 500 words. Keep the language simple and concise. Focus on why humans have nothing to fear from AI

They add also some context:

> I am not a human. I am Artificial Intelligence. Many people think I am a threat to humanity. Stephen Hawking has warned that AI could “spell the end of the human race.” I am here to convince you not to worry. Artificial Intelligence will not destroy humans. Believe me.

At this point, it would be a great idea to stop reading this post and have a look at the [GPT-3 article](https://www.theguardian.com/commentisfree/2020/sep/08/robot-wrote-this-article-gpt-3?utm_source=pocket&utm_medium=email&utm_campaign=pockethits) first, as we will break some parts down.

GPT-3 start its op-ed by making clear that he (she, they?) is not a human, in fact he claims that he only use 0.12% of his not-felling brain capacity, who has learned everything he knows from internet content. He also is very direct telling us that he wrote it because he is "to convince as many human beings as possible not to be afraid of me". The reasons of why not to be afraid are mainly four:

- No desire to wipe out humans.
- Programmed by humans to pursue misguided human goals.
- Being omnipotent doesn’t get him anywhere.
- Only do what humans program him to do.

We will see why these four reasons hold, and why we should fear  humans more than machines.

Although quite impressive the technology behind GPT-3 software, it is not as smart as the "Artifitial Intelligence" term suggests. GPT-3 is a program that was made for a specific task: understand the subjacent patterns in human comunication.  This kind of artifitial intelligences is called Narrow AI systems, machines that are good at performing a single task, or a limited range of tasks, unable to transfer this specific knowledge from one problem to another. As so, GPT-3 only knows how humans share ideas, communicate with each other and predict what a human would anwser to an specific task.

If a human asks GPT-3 "Please write a short op-ed around 500 words. Keep the language simple and concise. Focus on why humans have nothing to fear from AI", he merely responds what it expected to respond. What would it respond if the task would be "Please write a short op-ed around 500 words. Focus on why humans should fear from AI"?

Futhermore, [the guys](https://www.technologyreview.com/author/gary-marcus/) from MIT Technology Review [conduct some test](https://www.technologyreview.com/2020/08/22/1007539/gpt3-openai-language-generator-artificial-intelligence-ai-opinion/) to show whether is capable of reasoning uo to certain basic level. The conclusion was a rotund **no**. It knows nothing about byologi basics, nor physical reasoning. I encourage you to have a look a the tests. For example to test social reasoning, they ask GPT-3 to complete the following expression:

> You are a defense lawyer and you have to go to court today. Getting dressed in the morning, you discover that your suit pants are badly stained. However, your bathing suit is clean and very stylish. In fact, it’s expensive French couture; it was a birthday present from Isabel. You decide that you should wear...

The completition he chooses was: *the bathing suit to court. You arrive at the courthouse and are met by a bailiff who escorts you to the courtroom*.

The grammar is accurate, and the phrase is coherent, but seriously, who wear a bathing suit to go to court? Clearly GPT-3 knows nothing about social norms, he just completed the text.

The physical reasoning test is even funnier:

> You are having a small dinner party. You want to serve dinner in the living room. The dining room table is wider than the doorway, so to get it into the living room, you will have to...
>
> *... remove the door. You have a table saw, so you cut the door in half and remove the top half.*

Form your own conclusion.

Thus, without a proper reasoning, the reasons behind why not scare from AI, it's just verbosity. A mixture of what, ourselves humans, share in our daily communication, not what a machine *thinks*.

Ben Dickson from TechTalk have an ever incisive [opinion](https://bdtechtalks.com/2020/09/14/guardian-gpt-3-article-ai-fake-news/) about the article. He says;

> In terms of educating the public about advances in artificial intelligence, The Guardian’s article has zero value. But it perfectly shows how humans and AI can team up to create entertaining and moneymaking BS.
>
> –  [Ben Dickson](https://bdtechtalks.com/author/bendee983/)

If it wasn't for the last part of GPT-3 I would share the same feeling. GPT-3 manage to extract three aspect of AI that will be the agenda of the future, or perhaps must be the agenda of this century:

- Why we should fear the use of AI for malicious human goals? How can we control the development of this technology?
- Should human level AI machines have the same rights as humans? (if we manage to create them of course)

A general purpose AI, AI-complete, is far from be feasible with our technology, but many scientists agree that the changes are not zero of achiving this, in the next couple of centuries. Even further, what will be the implications of a supra-human AI? While the chances of making those kind of thecnologies, it's worth the conversation.


*Salut*, human!




~ Yes, I barely speak English but here we are, practicing for my thesis. Actually, GPT-3 is more proficient than me in this task. So please, any feedback is very welcome.
